[["index.html", "Watershed Analysis Chapter 1 Introduction 1.1 Course overview and objectives 1.2 Structure 1.3 Philosophical approach and books &amp; resources we will utilize 1.4 Tentative schedule, subject to change", " Watershed Analysis Tim Covino 2023-01-18 Chapter 1 Introduction This book provides the materials that we will use in Watershed Analysis (ENSC 445/545). In this class we will be learning the fundamentals of watershed analysis in R. Instructor: Dr. Tim Covino Class times: T 10:50 – 12:05; Th 10:50 – 12:05 Office hours: By appointment Website: https://tpcovino.github.io/ensc_445_545_bookdown 1.1 Course overview and objectives provide theoretical understanding and practical experience with common analysis and modeling techniques relevant to watershed hydrology. provide training in analyzing, simulating, and presenting scientific data in written and oral formats. 1.2 Structure This class will be largely hands-on, and students will be conducting watershed analyses and modeling exercises. We will be doing our analysis and modeling in R and will do some R coding in each class session. Programming is best learned by doing it often. We will generally have “lecture” on Tuesday, where we will talk about and work through various types of hydrological analyses. On Thursday’s you will then put the content from Tuesday to work in a lab where you will complete a variety of hydrological analyses in R. 1.3 Philosophical approach and books &amp; resources we will utilize This course will use all online and open-source resources and will follow FAIR (findability, accessibility, interoperability, and reusability) data principles and promote sharing of hydrological education and research materials. Our computing will utilze open source R and RStudio software. Books and readings will include R for Data Science and Statistical Methods in Water Resources, but other readings will be made available on this bookdown page as needed. We will promote an open, equitable, and collaborative environment such that we can all succeed and improve our skills in watershed analysis. 1.4 Tentative schedule, subject to change Week 1 (Unit 1): - Lecture (1/19): Introduction, overview, and technical skills. - Reading: Chapters 1, 2, &amp; 3 1-Welcome, 2-Introduction, &amp; 3-Data visualization in R for Data Science (RDS). Week 2 (Units 1 &amp; 2): - Lecture (1/24): Technical skills continued. Data visualization, data wrangling, and programming. - Lab 1 (1/26): Data visualization, data wrangling, and programming. - Reading: Chapter 2.1: Graphical Analysis of Single Datasets in Statistical Methods in Water Resources (SMWR). AND Chapters 4 &amp; 5 4-Workflow: Basics &amp; 5-Data transformation in RDS. Week 3 (Unit 3): - Lecture (1/31): Statistics in hydrology. - Lab 2 (2/2): Statistics in hydrology. - Reading: Chapter 1: 1-Summarizing Univariate Data in SMWR Week 4 (Unit 4): - Lecture (2/7): Downloading and shaping data frames. - Lab 3 (2/9): Downloading and shaping data frames. - Reading: The Experimental Forest Network, the Tenderfoot Creek Experimental Forest AND Introduction to the dataRetrieval package AND Chapter 12 &amp; 13 of R for Data Science Week 5 (Units 1 - 4): - Lecture (2/14): Term project overview and assign take home Exam 1. - Term project work session: project brainstorm, identify data, analysis, and models (if applicable) necessary to complete project. - Exam 1 part II (2/16): In class work and Exam 1 resubmission. Week 6 (Unit 5): - Lecture (2/21): Surface water: Rating curves and hydrographs. - Lab 4 (2/23): Rating curves and hydrographs - Reading: Chapter 4 4-Hypothesis Tests in SMWR. Week 7 (Unit 6): - Lecture (2/28): Flow frequency analysis (high and low flows) - Lab 5 (3/2): Flow frequency analysis - Reading: PeakFlow Frequency Estiamtes for USGS Streamflow-Gaging Stations in Connecticut AND Definitions and characteristics of low flows in EPA Environmental Modeling Community of Practice Week 8 (Unit 6 contd): - Lecture (3/7): Precipitation data acquisition and analysis - Lab 6 (3/9): Precipitation analysis - Reading: Frequency analysis of rainfall data Up to page 32. Week 9: Spring break (3/14 &amp; 3/16) - no class! Week 10 (Unit 7): - Lecture (3/21): Hydrologic processes, climate and water balance. Trend detection and analysis, non-parametric approaches. - Lab 7 (3/23): Trend analysis - Reading: Chapters 12.1 &amp; 12.2 12.1-General Structure of Trend Tests &amp; 12.2-Trend Tests with No Exogenous Variables in SMWR. Week 11 (Unit 8): - Lecture (3/28): Geospatial data in R - Lab (3/30): Term project work session and assign Exam 2 Week 12 (Units 5 - 8): - Lecture (4/4): Geospatial hydrology in R - Lab (4/6): In class work and Exam 1 resubmission. - Reading: Geocomputation with R AND Geospatial analysis in R Week 13 (Unit 9): - Lecture (4/11): Watershed delineation in R - Lab (4/13): Term project update presentations Week 14 (Unit 10): - Lecture (4/18): Hydrological modeling part 1 - Lab (4/20): Lab or term project work session (TBD) - Reading An Overview of Rainfall-Runoff Model Types Week 15 (Unit 10 contd): - Lecture (4/25): Hydrological modeling part 2 - Lab (4/27): Lab or term project work session (TBD) Week 16: Term project presentations (5/2 and 5/4) Week 17 (finals week): Final exam 5/9 10 - 11:50 AM (Units 1 - 10) "],["intro-to-data-visualization.html", "Chapter 2 Intro to data visualization 2.1 Download and install tidyverse library 2.2 Reading data 2.3 Our first ggplot 2.4 Change point type 2.5 Set colors 2.6 Controlling color with a third variable and other functions 2.7 Plotting multiple groups 2.8 Facets 2.9 Two variable faceting 2.10 Boxplots 2.11 More about color, size, etc 2.12 Multiple geoms", " Chapter 2 Intro to data visualization Follow this link to download everything you need for this unit. When you get to GitHub click on “Code” (green button) and select “download zip”. You will then save this to a local folder where you should do all of your work for this class. You will work through the “_blank.Rmd”. Always be sure to read the README.md files in the GitHub repo. Once you have this folder saved where you would like it, open RStudio and navigate to the folder. Next, open the project (“.Rproj”). Doing so will set the folder as the working directory, make your life easier, and make everything generally work. The use of projects is highly recommended and is the practice we will follow in this class. You will learn more about projects later, for now just know they are useful and make things easier. In this unit we want to start familiarizing ourselves with R by visualizing some hydrological data. The reading for this week will also begin to get you more familiar with R and RStudio (please read “1 Introduction”). 2.1 Download and install tidyverse library We will use the tidyverse a lot this semester. It is a suite of packages that handles plotting and data wrangling efficiently. You only have to install the library once. You have to load it using the library() function each time you start an R session. #install.packages(&quot;tidyverse&quot;) library(tidyverse) 2.2 Reading data The following lines will read in the data we will use for this exercise. Don’t worry about this right now beyond running it, we will talk more about it later. Pine &lt;- read_csv(&quot;PINE_Jan-Mar_2010.csv&quot;) ## Rows: 2160 Columns: 8 ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): StationID, surrogate ## dbl (5): cfs, year, quarter, month, day ## dttm (1): datetime ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. SNP &lt;- read_csv(&quot;PINE_NFDR_Jan-Mar_2010.csv&quot;) ## Rows: 4320 Columns: 8 ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): StationID, surrogate ## dbl (5): cfs, year, quarter, month, day ## dttm (1): datetime ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. RBI &lt;- read_csv(&quot;Flashy_Dat_Subset.csv&quot;) ## Rows: 49 Columns: 26 ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): STANAME, STATE, CLASS, AGGECOREGION ## dbl (22): site_no, RBI, RBIrank, DRAIN_SQKM, HUC02, LAT_GAGE, LNG_GAGE, PPTAVG_BASIN, PPTAVG_SITE, T_AVG_B... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Basic ggplot syntax 2.3 Our first ggplot Let’s look at the Pine data, plotting streamflow (the cfs column) by the date (datetime column). We will show the time series as a line. ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_line() 2.4 Change point type Now let’s make the same plot but show the data as points, using the pch parameter in geom_point() we can change the point type to any of the following: pch options from R help file ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_point(pch = 8) 2.5 Set colors We can also “easily” change the color. Easily is in quotes because this often trips people up. If you put color = “blue” in the aesthetic function, think about what that is telling ggplot. It says “control the color using”blue”“. That doesn’t make a whole lot of sense, so neither does the output… Try it. What happens is that if color = “blue” is in the aesthetic, you are telling R that the color used in the geom represents “blue”. This is very useful if you have multiple geoms in your plot, are coloring them differently, and are building a legend. But if you are just trying to color the points, it kind of feels like R is trolling you… doesn’t it? Take the color = “blue” out of the aesthetic and you’re golden. ggplot(data = Pine, aes(datetime, y = cfs, color = &quot;blue&quot;))+ geom_point() ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_point(color = &quot;blue&quot;) 2.6 Controlling color with a third variable and other functions Let’s plot the data as a line again, but play with it a bit. First: make the line blue Second: change the theme See ggplot themes here Third: change the axis labels Fourth: color by discharge See here for changing axis labels and coloring by a variable (in this case discharge) ggplot(data = Pine, aes(x = datetime, y = cfs, color = cfs))+ geom_line()+ ylab(&quot;Discharge (cfs)&quot;)+ xlab(element_blank())+ theme_classic() 2.7 Plotting multiple groups The SNP dataset has two different streams: Pine and NFDR We can look at the two of those a couple of different ways First, make two lines, colored by the stream by adding color = to your aesthetic. ggplot(data = SNP, aes(x = datetime,y = cfs, color = StationID)) + geom_line() 2.8 Facets We can also use facets. You must tell the facet_wrap what variable to use to make the separate panels (facet =). It’ll decide how to orient them or you can tell it how. We want them to be on top of each other so we are going to tell it we want 2 rows by setting nrow = 2. Note that we have to put the column used to make the facets in quotes after facets = ggplot(data = SNP, aes(x = datetime, y = cfs)) + geom_line() + facet_wrap(facets = &quot;StationID&quot;, nrow = 2) 2.9 Two variable faceting You can also use facet_grid() to break your plots up into panels based on two variables. Below we will create a panel for each month in each watershed. Adding scales = “free” allows facet_grid to change the axes. By default, all axes will be the same. This is often what we want, so we can more easily compare magnitudes, but sometimes we are looking for patterns more, so we may want to let the axes have whatever range works for the individual plots. ggplot(data = SNP, aes(x = datetime, y = cfs)) + geom_line() + facet_grid(StationID ~ month, scales = &quot;free&quot;) 2.10 Boxplots We can look at these data in other ways as well. A very useful way to look at the variation of two groups is to use a boxplot. Because the data span several orders of magnitude, we will have to log the y axis to see the differences between the two streams. We do that by adding scale_y_log10() ggplot(data = SNP, aes(x = StationID, y = cfs)) + stat_boxplot()+ scale_y_log10() 2.11 More about color, size, etc Let’s play around a bit with controlling color, point size, etc with other data. We can control the size of points by putting size = in the aes() and color by putting color = If you use a point type that has a background, like #21, you can also set the background color using bg = If points are too close together to see them all you can use a hollow point type or set the alpha lower so the points are transparent (alpha = ) ggplot(RBI, aes(RBI, DRAIN_SQKM, size = T_AVG_SITE, bg = STATE))+ geom_point(pch = 21, alpha = 0.3) 2.12 Multiple geoms Finally: You can add multiple geoms to the same plot. Examples of when you might want to do this are when you are showing a line fit and want to show the points as well, or maybe showing a boxplot and want to show the data behind it. You simply add additional geom_… lines to add additional geoms. ggplot(RBI, aes(RBI, DRAIN_SQKM, color = AGGECOREGION))+ stat_smooth(method = &quot;lm&quot;, linetype = 2)+ geom_point() ## `geom_smooth()` using formula = &#39;y ~ x&#39; "],["data-wrangling-using-tidyverse.html", "Chapter 3 Data wrangling using tidyverse 3.1 Introduction 3.2 You can use R as a calculator 3.3 You can create new objects using &lt;- 3.4 Using functions 3.5 Read in some data. 3.6 Wait, hold up. What is a tibble? 3.7 Data wrangling in dplyr 3.8 Filter 3.9 Arrange 3.10 Select 3.11 Mutate 3.12 Summarize 3.13 Multiple operations with pipes 3.14 Save your results to a new tibble 3.15 What about NAs? 3.16 What are some things you think I’ll ask you to do for the activity next class?", " Chapter 3 Data wrangling using tidyverse Follow this link to download everything you need for this unit. When you get to GitHub click on “Code” (green button) and select “download zip”. You will then save this to a local folder where you should do all of your work for this class. You will work through the “_blank.Rmd”. Always be sure to read the README.md files in the GitHub repo. Once you have this folder saved where you would like it, open RStudio and navigate to the folder. Next, open the project (“.Rproj”). Doing so will set the folder as the working directory, make your life easier, and make everything generally work. 3.1 Introduction We have messed around with plotting a bit and you’ve seen a little of what R can do. So now let’s review or introduce you to some basics. Even if you have worked in R before, it is good to be remind of/practice with this stuff, so stay tuned in! This exercise covers most of the same principles as two chapters in R for Data Science Workflow: basics Data transformation 3.2 You can use R as a calculator If you just type numbers and operators in, R will spit out the results 1 + 2 ## [1] 3 3.3 You can create new objects using &lt;- Yea yea, = does the same thing. But use &lt;-. We will call &lt;- assignment or assignment operator. When we are coding in R we use &lt;- to assign values to objects and = to set values for parameters in functions. Using &lt;- helps us differentiate between the two. Norms for formatting are important because they help us understand what code is doing, especially when stuff gets complex. Oh, one more thing: Surround operators with spaces. Don’t code like a gorilla. x &lt;- 1 looks better than x&lt;-1 and if you disagree you are wrong. :) You can assign single numbers or entire chunks of data using &lt;- So if you had an object called my_data and wanted to copy it into my_new_data you could do: my_new_data &lt;- my_data You can then recall/print the values in an object by just typing the name by itself. In the code chunk below, assign a 3 to the object “y” and then print it out. y &lt;- 3 y ## [1] 3 If you want to assign multiple values, you have to put them in the function c() c means combine. R doesn’t know what to do if you just give it a bunch of values with space or commas, but if you put them as arguments in the combine function, it’ll make them into a vector. Any time you need to use several values, even passing as an argument to a function, you have to put them in c() or it won’t work. a &lt;- c(1,2,3,4) a ## [1] 1 2 3 4 When you are creating objects, try to give them meaningful names so you can remember what they are. You can’t have spaces or operators that mean something else as part of a name. And remember, everything is case sensitive. Assign the value 5.4 to water_pH and then try to recall it by typing “water_ph” water_pH &lt;- 5.4 #water_ph If we want to remove something from the environment we can use rm(). Try to remove water_pH. You can also set objects equal to strings, or values that have letters in them. To do this you just have to put the value in quotes, otherwise R will think it is an object name and tell you it doesn’t exist. Try: name &lt;- “your name” and then name &lt;- your name What happens if you forget the ending parenthesis? Try: name &lt;- “your name R can be cryptic with it’s error messages or other responses, but once you get used to them, you know exactly what is wrong when they pop up. As a note - when you go to the internet for example code it will often say things like df &lt;- your_data, this is similar to what I’ve written above: name &lt;- “your name”. It means enter you name (or your data). As you progress you will get better at understanding example code and understanding error messages. name &lt;- &quot;Tim&quot; #name &lt;- Tim 3.4 Using functions As an example, let’s try the seq() function, which creates a sequence of numbers. seq(from = 1, to = 10, by = 1) ## [1] 1 2 3 4 5 6 7 8 9 10 #or seq(1, 10, 1) ## [1] 1 2 3 4 5 6 7 8 9 10 #or seq(1, 10) ## [1] 1 2 3 4 5 6 7 8 9 10 #what does this do seq(10,1) ## [1] 10 9 8 7 6 5 4 3 2 1 3.5 Read in some data. For the following demonstration we will use the RBI data from a sample of USGS gages we used last class. First we will load the tidyverse library, everything we have done so far today is in base R. Important: read_csv() is the tidyverse csv reading function, the base R function is read.csv(). read.csv() will not read your data in as a tibble, which is the format used by tidyverse functions. You should get in the habit of using the tidyverse versions such as read_csv(). library(tidyverse) rbi &lt;- read_csv(&quot;Flashy_Dat_Subset.csv&quot;) ## Rows: 49 Columns: 26 ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): STANAME, STATE, CLASS, AGGECOREGION ## dbl (22): site_no, RBI, RBIrank, DRAIN_SQKM, HUC02, LAT_GAGE, LNG_GAGE, PPTAVG_BASIN, PPTAVG_SITE, T_AVG_B... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. test_df &lt;- read.csv(&quot;Flashy_Dat_Subset.csv&quot;) 3.6 Wait, hold up. What is a tibble? Good question. It’s a fancy way to store data that works well with tidyverse functions. Let’s look at the rbi tibble. head(rbi) ## # A tibble: 6 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1013500 0.0584 35 Fish River… 2253. 1 47.2 -68.6 ME Ref NorthE… 97.4 93.5 3 ## 2 1021480 0.208 300 Old Stream… 76.7 1 44.9 -67.7 ME Ref NorthE… 115. 117. 5.71 ## 3 1022500 0.198 286 Narraguagu… 574. 1 44.6 -67.9 ME Ref NorthE… 120. 130. 5.95 ## 4 1029200 0.132 183 Seboeis Ri… 445. 1 46.1 -68.6 ME Ref NorthE… 102. 103. 3.61 ## 5 1030500 0.114 147 Mattawamke… 3676. 1 45.5 -68.3 ME Ref NorthE… 108. 113. 4.82 ## 6 1031300 0.297 489 Piscataqui… 304. 1 45.3 -69.6 ME Ref NorthE… 120. 121. 3.6 ## # … with 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, T_MAX_SITE &lt;dbl&gt;, ## # T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, SNOW_PCT_PRECIP &lt;dbl&gt;, ## # PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated variable names ## # ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ⁷​T_AVG_BASIN head(test_df) ## site_no RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE ## 1 1013500 0.05837454 35 Fish River near Fort Kent, Maine 2252.7 1 47.23739 -68.58264 ## 2 1021480 0.20797008 300 Old Stream near Wesley, Maine 76.7 1 44.93694 -67.73611 ## 3 1022500 0.19805382 286 Narraguagus River at Cherryfield, Maine 573.6 1 44.60797 -67.93524 ## 4 1029200 0.13151299 183 Seboeis River near Shin Pond, Maine 444.9 1 46.14306 -68.63361 ## 5 1030500 0.11350485 147 Mattawamkeag River near Mattawamkeag, Maine 3676.2 1 45.50097 -68.30596 ## 6 1031300 0.29718786 489 Piscataquis River at Blanchard, Maine 304.4 1 45.26722 -69.58389 ## STATE CLASS AGGECOREGION PPTAVG_BASIN PPTAVG_SITE T_AVG_BASIN T_AVG_SITE T_MAX_BASIN T_MAXSTD_BASIN ## 1 ME Ref NorthEast 97.42 93.53 3.00 3.0 9.67 0.202 ## 2 ME Ref NorthEast 115.39 117.13 5.71 5.8 11.70 0.131 ## 3 ME Ref NorthEast 120.07 129.56 5.95 6.3 11.90 0.344 ## 4 ME Ref NorthEast 102.19 103.24 3.61 4.0 9.88 0.231 ## 5 ME Ref NorthEast 108.19 113.13 4.82 5.4 10.75 0.554 ## 6 ME Ref NorthEast 119.83 120.93 3.60 4.2 9.57 0.431 ## T_MAX_SITE T_MIN_BASIN T_MINSTD_BASIN T_MIN_SITE PET SNOW_PCT_PRECIP PRECIP_SEAS_IND FLOWYRS_1990_2009 ## 1 10.0 -2.49 0.269 -2.7 504.7 36.9 0.102 20 ## 2 11.9 -0.85 0.123 -0.6 554.2 39.5 0.046 11 ## 3 12.2 0.06 0.873 1.4 553.1 38.2 0.047 20 ## 4 10.4 -2.13 0.216 -1.5 513.0 36.4 0.070 11 ## 5 11.7 -1.49 0.251 -1.2 540.8 37.2 0.033 20 ## 6 11.0 -2.46 0.268 -1.7 495.8 40.2 0.030 13 ## wy00_09 ## 1 10 ## 2 10 ## 3 10 ## 4 10 ## 5 10 ## 6 10 Now read in the same data with read.csv() which will NOT read the data as a tibble. How is it different? Output each one in the Console. Knowing the data type for each column is super helpful for a few reasons…. let’s talk about them. Types: int, dbl, fctr, char, logical rbi_NT &lt;- read.csv(&quot;Flashy_Dat_Subset.csv&quot;) head(rbi_NT) ## site_no RBI RBIrank STANAME DRAIN_SQKM HUC02 LAT_GAGE LNG_GAGE ## 1 1013500 0.05837454 35 Fish River near Fort Kent, Maine 2252.7 1 47.23739 -68.58264 ## 2 1021480 0.20797008 300 Old Stream near Wesley, Maine 76.7 1 44.93694 -67.73611 ## 3 1022500 0.19805382 286 Narraguagus River at Cherryfield, Maine 573.6 1 44.60797 -67.93524 ## 4 1029200 0.13151299 183 Seboeis River near Shin Pond, Maine 444.9 1 46.14306 -68.63361 ## 5 1030500 0.11350485 147 Mattawamkeag River near Mattawamkeag, Maine 3676.2 1 45.50097 -68.30596 ## 6 1031300 0.29718786 489 Piscataquis River at Blanchard, Maine 304.4 1 45.26722 -69.58389 ## STATE CLASS AGGECOREGION PPTAVG_BASIN PPTAVG_SITE T_AVG_BASIN T_AVG_SITE T_MAX_BASIN T_MAXSTD_BASIN ## 1 ME Ref NorthEast 97.42 93.53 3.00 3.0 9.67 0.202 ## 2 ME Ref NorthEast 115.39 117.13 5.71 5.8 11.70 0.131 ## 3 ME Ref NorthEast 120.07 129.56 5.95 6.3 11.90 0.344 ## 4 ME Ref NorthEast 102.19 103.24 3.61 4.0 9.88 0.231 ## 5 ME Ref NorthEast 108.19 113.13 4.82 5.4 10.75 0.554 ## 6 ME Ref NorthEast 119.83 120.93 3.60 4.2 9.57 0.431 ## T_MAX_SITE T_MIN_BASIN T_MINSTD_BASIN T_MIN_SITE PET SNOW_PCT_PRECIP PRECIP_SEAS_IND FLOWYRS_1990_2009 ## 1 10.0 -2.49 0.269 -2.7 504.7 36.9 0.102 20 ## 2 11.9 -0.85 0.123 -0.6 554.2 39.5 0.046 11 ## 3 12.2 0.06 0.873 1.4 553.1 38.2 0.047 20 ## 4 10.4 -2.13 0.216 -1.5 513.0 36.4 0.070 11 ## 5 11.7 -1.49 0.251 -1.2 540.8 37.2 0.033 20 ## 6 11.0 -2.46 0.268 -1.7 495.8 40.2 0.030 13 ## wy00_09 ## 1 10 ## 2 10 ## 3 10 ## 4 10 ## 5 10 ## 6 10 3.7 Data wrangling in dplyr If you forget syntax or what the following functions do, here is an excellent cheat sheet: https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf We will demo five functions below: filter() - returns rows that meet specified conditions arrange() - reorders rows select() - pull out variables (columns) mutate() - create new variables (columns) or reformat existing ones summarize() - collapse groups of values into summary stats With all of these, the first argument is the data and then the arguments after that specify what you want the function to do. 3.8 Filter Write an expression that returns data in rbi for the state of Maine (ME) Operators: == equal != not equal &gt;= , &lt;= greater than or equal to, less than or equal to &gt;, &lt; greater than or less then %in% included in a list of values &amp; and | or filter(rbi, STATE == &quot;ME&quot;) ## # A tibble: 13 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1013500 0.0584 35 Fish Rive… 2253. 1 47.2 -68.6 ME Ref NorthE… 97.4 93.5 3 ## 2 1021480 0.208 300 Old Strea… 76.7 1 44.9 -67.7 ME Ref NorthE… 115. 117. 5.71 ## 3 1022500 0.198 286 Narraguag… 574. 1 44.6 -67.9 ME Ref NorthE… 120. 130. 5.95 ## 4 1029200 0.132 183 Seboeis R… 445. 1 46.1 -68.6 ME Ref NorthE… 102. 103. 3.61 ## 5 1030500 0.114 147 Mattawamk… 3676. 1 45.5 -68.3 ME Ref NorthE… 108. 113. 4.82 ## 6 1031300 0.297 489 Piscataqu… 304. 1 45.3 -69.6 ME Ref NorthE… 120. 121. 3.6 ## 7 1031500 0.320 545 Piscataqu… 769 1 45.2 -69.3 ME Ref NorthE… 118 114. 4.14 ## 8 1037380 0.318 537 Ducktrap … 39 1 44.3 -69.1 ME Ref NorthE… 122. 123. 7.22 ## 9 1044550 0.242 360 Spencer S… 500. 1 45.3 -70.2 ME Ref NorthE… 110. 102. 2.54 ## 10 1047000 0.344 608 Carrabass… 909. 1 44.9 -70.0 ME Ref NorthE… 119. 106. 3.99 ## 11 1054200 0.492 805 Wild Rive… 181 1 44.4 -71.0 ME Ref NorthE… 136. 106. 4.81 ## 12 1055000 0.450 762 Swift Riv… 251. 1 44.6 -70.6 ME Ref NorthE… 135. 119. 3.81 ## 13 1057000 0.326 561 Little An… 191. 1 44.3 -70.5 ME Ref NorthE… 108. 105. 5.88 ## # … with 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, T_MAX_SITE &lt;dbl&gt;, ## # T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, SNOW_PCT_PRECIP &lt;dbl&gt;, ## # PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated variable names ## # ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ⁷​T_AVG_BASIN 3.8.1 Multiple conditions How many gages are there in Maine with an rbi greater than 0.25 filter(rbi, STATE == &quot;ME&quot; &amp; RBI &gt; 0.25) ## # A tibble: 7 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1031300 0.297 489 Piscataquis… 304. 1 45.3 -69.6 ME Ref NorthE… 120. 121. 3.6 ## 2 1031500 0.320 545 Piscataquis… 769 1 45.2 -69.3 ME Ref NorthE… 118 114. 4.14 ## 3 1037380 0.318 537 Ducktrap Ri… 39 1 44.3 -69.1 ME Ref NorthE… 122. 123. 7.22 ## 4 1047000 0.344 608 Carrabasset… 909. 1 44.9 -70.0 ME Ref NorthE… 119. 106. 3.99 ## 5 1054200 0.492 805 Wild River … 181 1 44.4 -71.0 ME Ref NorthE… 136. 106. 4.81 ## 6 1055000 0.450 762 Swift River… 251. 1 44.6 -70.6 ME Ref NorthE… 135. 119. 3.81 ## 7 1057000 0.326 561 Little Andr… 191. 1 44.3 -70.5 ME Ref NorthE… 108. 105. 5.88 ## # … with 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, T_MAX_SITE &lt;dbl&gt;, ## # T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, SNOW_PCT_PRECIP &lt;dbl&gt;, ## # PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated variable names ## # ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ⁷​T_AVG_BASIN 3.9 Arrange Arrange sorts by a column in your dataset. Sort the rbi data by the RBI column in ascending and then descending order arrange(rbi, RBI) ## # A tibble: 49 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1305500 0.0464 18 SWAN RIVE… 21.3 2 40.8 -73.0 NY Non-… SECstP… 125. 125. 10.9 ## 2 1013500 0.0584 35 Fish Rive… 2253. 1 47.2 -68.6 ME Ref NorthE… 97.4 93.5 3 ## 3 1306460 0.0587 37 CONNETQUO… 55.7 2 40.8 -73.2 NY Non-… SECstP… 122. 123. 11.0 ## 4 1030500 0.114 147 Mattawamk… 3676. 1 45.5 -68.3 ME Ref NorthE… 108. 113. 4.82 ## 5 1029200 0.132 183 Seboeis R… 445. 1 46.1 -68.6 ME Ref NorthE… 102. 103. 3.61 ## 6 1117468 0.172 244 BEAVER RI… 25.3 1 41.5 -71.6 RI Ref NorthE… 128. 129. 9.73 ## 7 1022500 0.198 286 Narraguag… 574. 1 44.6 -67.9 ME Ref NorthE… 120. 130. 5.95 ## 8 1021480 0.208 300 Old Strea… 76.7 1 44.9 -67.7 ME Ref NorthE… 115. 117. 5.71 ## 9 1162500 0.213 311 PRIEST BR… 49.7 1 42.7 -72.1 MA Ref NorthE… 121. 118. 6.68 ## 10 1117370 0.230 338 QUEEN R A… 50.5 1 41.5 -71.6 RI Ref NorthE… 127. 129. 9.78 ## # … with 39 more rows, 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, ## # T_MAX_SITE &lt;dbl&gt;, T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, ## # SNOW_PCT_PRECIP &lt;dbl&gt;, PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated ## # variable names ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ## # ⁷​T_AVG_BASIN arrange(rbi, desc(RBI)) ## # A tibble: 49 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1311500 0.856 1017 VALLEY STR… 18.1 2 40.7 -73.7 NY Non-… SECstP… 124. 124. 11.8 ## 2 1054200 0.492 805 Wild River… 181 1 44.4 -71.0 ME Ref NorthE… 136. 106. 4.81 ## 3 1187300 0.487 800 HUBBARD RI… 53.9 1 42.0 -72.9 MA Ref NorthE… 135. 131. 7.14 ## 4 1105600 0.484 797 OLD SWAMP … 12.7 1 42.2 -70.9 MA Non-… NorthE… 119. 120. 9.61 ## 5 1055000 0.450 762 Swift Rive… 251. 1 44.6 -70.6 ME Ref NorthE… 135. 119. 3.81 ## 6 1195100 0.430 744 INDIAN RIV… 14.8 1 41.3 -72.5 CT Ref NorthE… 128. 127. 9.95 ## 7 1181000 0.420 732 WEST BRANC… 244. 1 42.2 -72.9 MA Ref NorthE… 144. 129. 7.33 ## 8 1350000 0.414 721 SCHOHARIE … 612. 2 42.3 -74.4 NY Ref NorthE… 119. 101. 5.66 ## 9 1121000 0.404 710 MOUNT HOPE… 70.3 1 41.8 -72.2 CT Ref NorthE… 128. 130. 8.52 ## 10 1169000 0.395 688 NORTH RIVE… 231. 1 42.6 -72.7 MA Ref NorthE… 131. 125. 6.6 ## # … with 39 more rows, 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, ## # T_MAX_SITE &lt;dbl&gt;, T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, ## # SNOW_PCT_PRECIP &lt;dbl&gt;, PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated ## # variable names ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ## # ⁷​T_AVG_BASIN 3.10 Select There are too many columns! You will often want to do this when you are manipulating the structure of your data and need to trim it down to only include what you will use. Select Site name, state, and RBI from the rbi data Note they come back in the order you put them in in the function, not the order they were in in the original data. You can do a lot more with select, especially when you need to select a bunch of columns but don’t want to type them all out. But we don’t need to cover all that today. For a taste though, if you want to select a group of columns you can specify the first and last with a colon in between (first:last) and it’ll return all of them. Select the rbi columns from site_no to DRAIN_SQKM. select(rbi, STANAME, STATE, RBI) ## # A tibble: 49 × 3 ## STANAME STATE RBI ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Fish River near Fort Kent, Maine ME 0.0584 ## 2 Old Stream near Wesley, Maine ME 0.208 ## 3 Narraguagus River at Cherryfield, Maine ME 0.198 ## 4 Seboeis River near Shin Pond, Maine ME 0.132 ## 5 Mattawamkeag River near Mattawamkeag, Maine ME 0.114 ## 6 Piscataquis River at Blanchard, Maine ME 0.297 ## 7 Piscataquis River near Dover-Foxcroft, Maine ME 0.320 ## 8 Ducktrap River near Lincolnville, Maine ME 0.318 ## 9 Spencer Stream near Grand Falls, Maine ME 0.242 ## 10 Carrabassett River near North Anson, Maine ME 0.344 ## # … with 39 more rows select(rbi, site_no:DRAIN_SQKM) ## # A tibble: 49 × 5 ## site_no RBI RBIrank STANAME DRAIN_SQKM ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1013500 0.0584 35 Fish River near Fort Kent, Maine 2253. ## 2 1021480 0.208 300 Old Stream near Wesley, Maine 76.7 ## 3 1022500 0.198 286 Narraguagus River at Cherryfield, Maine 574. ## 4 1029200 0.132 183 Seboeis River near Shin Pond, Maine 445. ## 5 1030500 0.114 147 Mattawamkeag River near Mattawamkeag, Maine 3676. ## 6 1031300 0.297 489 Piscataquis River at Blanchard, Maine 304. ## 7 1031500 0.320 545 Piscataquis River near Dover-Foxcroft, Maine 769 ## 8 1037380 0.318 537 Ducktrap River near Lincolnville, Maine 39 ## 9 1044550 0.242 360 Spencer Stream near Grand Falls, Maine 500. ## 10 1047000 0.344 608 Carrabassett River near North Anson, Maine 909. ## # … with 39 more rows 3.11 Mutate Use mutate to add new columns based on additional ones. Common uses are to create a column of data in different units, or to calculate something based on two columns. You can also use it to just update a column, by naming the new column the same as the original one (but be careful because you’ll lose the original one!). I commonly use this when I am changing the datatype of a column, say from a character to a factor or a string to a date. Create a new column in rbi called T_RANGE by subtracting T_MIN_SITE from T_MAX_SITE mutate(rbi, T_RANGE = T_MAX_SITE - T_MIN_SITE) ## # A tibble: 49 × 27 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1013500 0.0584 35 Fish Rive… 2253. 1 47.2 -68.6 ME Ref NorthE… 97.4 93.5 3 ## 2 1021480 0.208 300 Old Strea… 76.7 1 44.9 -67.7 ME Ref NorthE… 115. 117. 5.71 ## 3 1022500 0.198 286 Narraguag… 574. 1 44.6 -67.9 ME Ref NorthE… 120. 130. 5.95 ## 4 1029200 0.132 183 Seboeis R… 445. 1 46.1 -68.6 ME Ref NorthE… 102. 103. 3.61 ## 5 1030500 0.114 147 Mattawamk… 3676. 1 45.5 -68.3 ME Ref NorthE… 108. 113. 4.82 ## 6 1031300 0.297 489 Piscataqu… 304. 1 45.3 -69.6 ME Ref NorthE… 120. 121. 3.6 ## 7 1031500 0.320 545 Piscataqu… 769 1 45.2 -69.3 ME Ref NorthE… 118 114. 4.14 ## 8 1037380 0.318 537 Ducktrap … 39 1 44.3 -69.1 ME Ref NorthE… 122. 123. 7.22 ## 9 1044550 0.242 360 Spencer S… 500. 1 45.3 -70.2 ME Ref NorthE… 110. 102. 2.54 ## 10 1047000 0.344 608 Carrabass… 909. 1 44.9 -70.0 ME Ref NorthE… 119. 106. 3.99 ## # … with 39 more rows, 13 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, ## # T_MAX_SITE &lt;dbl&gt;, T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, ## # SNOW_PCT_PRECIP &lt;dbl&gt;, PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, T_RANGE &lt;dbl&gt;, and ## # abbreviated variable names ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ## # ⁷​T_AVG_BASIN When downloading data from the USGS through R, you have to enter the gage ID as a character, even though they are all made up of numbers. So to practice doing this, update the site_no column to be a character datatype mutate(rbi, site_no = as.character(site_no)) ## # A tibble: 49 × 26 ## site_no RBI RBIrank STANAME DRAIN…¹ HUC02 LAT_G…² LNG_G…³ STATE CLASS AGGEC…⁴ PPTAV…⁵ PPTAV…⁶ T_AVG…⁷ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1013500 0.0584 35 Fish Rive… 2253. 1 47.2 -68.6 ME Ref NorthE… 97.4 93.5 3 ## 2 1021480 0.208 300 Old Strea… 76.7 1 44.9 -67.7 ME Ref NorthE… 115. 117. 5.71 ## 3 1022500 0.198 286 Narraguag… 574. 1 44.6 -67.9 ME Ref NorthE… 120. 130. 5.95 ## 4 1029200 0.132 183 Seboeis R… 445. 1 46.1 -68.6 ME Ref NorthE… 102. 103. 3.61 ## 5 1030500 0.114 147 Mattawamk… 3676. 1 45.5 -68.3 ME Ref NorthE… 108. 113. 4.82 ## 6 1031300 0.297 489 Piscataqu… 304. 1 45.3 -69.6 ME Ref NorthE… 120. 121. 3.6 ## 7 1031500 0.320 545 Piscataqu… 769 1 45.2 -69.3 ME Ref NorthE… 118 114. 4.14 ## 8 1037380 0.318 537 Ducktrap … 39 1 44.3 -69.1 ME Ref NorthE… 122. 123. 7.22 ## 9 1044550 0.242 360 Spencer S… 500. 1 45.3 -70.2 ME Ref NorthE… 110. 102. 2.54 ## 10 1047000 0.344 608 Carrabass… 909. 1 44.9 -70.0 ME Ref NorthE… 119. 106. 3.99 ## # … with 39 more rows, 12 more variables: T_AVG_SITE &lt;dbl&gt;, T_MAX_BASIN &lt;dbl&gt;, T_MAXSTD_BASIN &lt;dbl&gt;, ## # T_MAX_SITE &lt;dbl&gt;, T_MIN_BASIN &lt;dbl&gt;, T_MINSTD_BASIN &lt;dbl&gt;, T_MIN_SITE &lt;dbl&gt;, PET &lt;dbl&gt;, ## # SNOW_PCT_PRECIP &lt;dbl&gt;, PRECIP_SEAS_IND &lt;dbl&gt;, FLOWYRS_1990_2009 &lt;dbl&gt;, wy00_09 &lt;dbl&gt;, and abbreviated ## # variable names ¹​DRAIN_SQKM, ²​LAT_GAGE, ³​LNG_GAGE, ⁴​AGGECOREGION, ⁵​PPTAVG_BASIN, ⁶​PPTAVG_SITE, ## # ⁷​T_AVG_BASIN 3.12 Summarize Summarize will perform an operation on all of your data, or groups if you assign groups. Use summarize to compute the mean, min, and max rbi summarize(rbi, meanrbi = mean(RBI), maxrbi = max(RBI), minrbi = min(RBI)) ## # A tibble: 1 × 3 ## meanrbi maxrbi minrbi ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.316 0.856 0.0464 Now use the group function to group by state and then summarize in the same way as above rbistate &lt;- group_by(rbi, STATE) summarize(rbistate, meanrbi = mean(RBI), maxrbi = max(RBI), minrbi = min(RBI)) ## # A tibble: 7 × 4 ## STATE meanrbi maxrbi minrbi ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CT 0.366 0.430 0.295 ## 2 MA 0.367 0.487 0.213 ## 3 ME 0.269 0.492 0.0584 ## 4 NH 0.336 0.368 0.265 ## 5 NY 0.342 0.856 0.0464 ## 6 RI 0.201 0.230 0.172 ## 7 VT 0.299 0.365 0.231 3.13 Multiple operations with pipes The pipe operator %&gt;% allows you to perform multiple operations in a sequence without saving intermediate steps. Not only is this more efficient, but structuring operations with pipes is also more intuitive than nesting functions within functions (the other way you can do multiple operations). 3.13.1 Let’s say we want to tell R to make a PB&amp;J sandwich by using the pbbread(), jbread(), and joinslices() functions and the data “ingredients”. If we do this saving each step if would look like this: sando &lt;- pbbread(ingredients) sando &lt;- jbread(sando) sando &lt;- joinslices(sando) 3.13.2 If we nest the functions together we get this joinslice(jbread(pbbread(ingredients))) Efficient… but tough to read/interpret 3.13.3 Using the pipe it would look like this ingredients %&gt;% pbbread() %&gt;% jbread() %&gt;% joinslices() Much easier to follow! 3.13.4 When you use the pipe, it basically takes whatever came out of the first function and puts it into the data argument for the next one so rbi %&gt;% group_by(STATE) is the same as group_by(rbi, STATE) Take the groupby and summarize code from above and perform the operation using the pipe rbi %&gt;% group_by(STATE) %&gt;% summarize(meanrbi = mean(RBI), maxrbi = max(RBI), minrbi = min(RBI)) ## # A tibble: 7 × 4 ## STATE meanrbi maxrbi minrbi ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CT 0.366 0.430 0.295 ## 2 MA 0.367 0.487 0.213 ## 3 ME 0.269 0.492 0.0584 ## 4 NH 0.336 0.368 0.265 ## 5 NY 0.342 0.856 0.0464 ## 6 RI 0.201 0.230 0.172 ## 7 VT 0.299 0.365 0.231 3.14 Save your results to a new tibble We have just been writing everything to the screen so we can see what we are doing… In order to save anything we do with these functions to work with it later, we just have to use the assignment operator (&lt;-) to store the data. One kind of awesome thing about the assignment operator is that it works both ways… x &lt;- 3 and 3 -&gt; x do the same thing (WHAT?!) So you can do the assignment at the beginning or the end of your dplyr workings, whatever you like best. Use the assignment operator to save the summary table you just made. stateRBIs &lt;- rbi %&gt;% group_by(STATE) %&gt;% summarize(meanrbi = mean(RBI), maxrbi = max(RBI), minrbi = min(RBI)) # Notice when you do this it doesn&#39;t output the result... # You can see what you did by clickon in stateRBIs in your environment panel # or just type stateRBIs stateRBIs ## # A tibble: 7 × 4 ## STATE meanrbi maxrbi minrbi ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CT 0.366 0.430 0.295 ## 2 MA 0.367 0.487 0.213 ## 3 ME 0.269 0.492 0.0584 ## 4 NH 0.336 0.368 0.265 ## 5 NY 0.342 0.856 0.0464 ## 6 RI 0.201 0.230 0.172 ## 7 VT 0.299 0.365 0.231 3.15 What about NAs? We will talk more about this when we discuss stats, but some operations will fail if there are NA’s in the data. If appropriate, you can tell functions like mean() to ignore NAs by using na.rm = TRUE. You can also use drop_na() if you’re working with a tibble. But be aware if you use that and save the result, drop_na() gets rid of the whole row, not just the NA. Because what would you replace it with…. an NA? First, lets create a small data frame called x that includes: 1, 2, 3, 4, NA. How do we do that? x &lt;- c(1,2,3,4,NA) Next, lets take the mean of x. mean(x) ## [1] NA How do you think we can fix this problem? mean(x, na.rm = TRUE) ## [1] 2.5 3.16 What are some things you think I’ll ask you to do for the activity next class? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
