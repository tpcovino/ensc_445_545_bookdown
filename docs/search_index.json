[["index.html", "Watershed Analysis Chapter 1 Introduction 1.1 Course overview and objectives: 1.2 Structure: 1.3 Philosophical approach and books &amp; resources we will utilize: 1.4 Tentative schedule, subject to change:", " Watershed Analysis Tim Covino 2022-11-17 Chapter 1 Introduction This book provides the materials that we will use in Watershed Analysis (ENSC 445/545). In this class we will be learning the fundamentals of watershed analysis in R. Instructor: Dr. Tim Covino Class times: T 14:00 – 15:15; Th 14:00 – 15:15 Office hours: W 14:00 - 15:15; or by appointment Website: https://tpcovino.github.io/ensc_445_545_bookdown 1.1 Course overview and objectives: provide theoretical understanding and practical experience with the most common analysis and modeling techniques relevant to watershed hydrology; provide training in analyzing, simulating, and presenting scientific data in written and oral formats. 1.2 Structure: This class will be largely hands-on, and students will be conducting watershed analyses and modeling exercises. We will follow a typical weekly format of Tuesday in-class lecture and activities, Thursday hands-on computational work, and time spent working through online modules outside of class. The online modules are required and are intended to prepare students for the in-class work during lab on Thursday. Accordingly, this class will follow a semi-flipped format that includes in-class lecture, online modules, and in-class work sessions. 1.3 Philosophical approach and books &amp; resources we will utilize: This course will use all online and open-source resources and will follow FAIR (findability, accessibility, interoperability, and reusability) data principles and promote sharing of hydrological education and research materials. Our computing will utilze open source R and RStudio software. Books and readings will include R for Data Science and Statistical Methods in Water Resources, but other readings will be made available on this bookdown page as needed. We will promote an open, equitable, and collaborative environment such that we can all succeed and improve our skills in watershed analysis. 1.4 Tentative schedule, subject to change: Week 1 (Unit 1): Introduction, overview, and technical skills. Reading Chapters 1, 2, &amp; 3 1-Welcome, 2-Introduction, &amp; 3-Data visualization in R for Data Science (RDS). Week 2 (Units 1 &amp; 2): Technical skills continued. Data visualization, data wrangling, and programming. Reading Chapter 2.1: Graphical Analysis of Single Datasets in Statistical Methods in Water Resources (SMWR). AND Chapters 4 &amp; 5 4-Workflow: Basics &amp; 5-Data transformation in RDS. Week 3 (Unit 3): Statistics in hydrology. Reading Chapter 1: 1-Summarizing Univariate Data in SMWR Week 4 (Unit 4): Hydrologic processes, climate and water balance. Trend detection and analysis, non-parametric approaches. Reading Chapters 12.1 &amp; 12.2 12.1-General Structure of Trend Tests &amp; 12.2-Trend Tests with No Exogenous Variables in SMWR. Week 5: Term project overview and Exam 1. Term project: project brainstorm, identify data, analysis, and models (if applicable) necessary to complete project. Week 6 (Unit 5): Surface water: Rating curves, hydrographs, and exceedence analysis. Reading Chapter 4 4-Hypothesis Tests in SMWR. Week 7: Low flow analysis Week 8: Flood frequency analysis Week 9: Spring break - no class! "],["intro-to-data-visualization.html", "Chapter 2 Intro to data visualization 2.1 Download and install tidyverse library 2.2 Reading data 2.3 Our first ggplot 2.4 Change point type 2.5 Set colors 2.6 Controlling color with a third variable and other functions 2.7 Plotting multiple groups 2.8 Facets 2.9 Two variable faceting 2.10 Boxplots 2.11 More about color, size, etc 2.12 Multiple geoms", " Chapter 2 Intro to data visualization Follow this link to download everything you need for this unit. When you get to GitHub click on “Code” (green button) and select “download zip”. You will then save this to a local folder where you should do all of your work for this class. You will work through the “_blank.Rmd”. Always be sure to read the README.md files in the GitHub repo. Once you have this folder saved where you would like it, open RStudio and navigate to the folder. Next, open the project (“.Rproj”). Doing so will set the folder as the working directory, make your life easier, and make everything generally work. The use of projects is highly recommended and is the practice we will follow in this class. You will learn more about projects later, for now just know they are useful and make things easier. In this unit we want to start familiarizing ourselves with R by visualizing some hydrological data. The reading for this week will also begin to get you more familiar with R and RStudio (please read “1 Introduction”). 2.1 Download and install tidyverse library We will use the tidyverse a lot this semester. It is a suite of packages that handles plotting and data wrangling efficiently. You only have to install the library once. You have to load it using the library() function each time you start an R session. #install.packages(&quot;tidyverse&quot;) library(tidyverse) 2.2 Reading data The following lines will read in the data we will use for this exercise. Don’t worry about this right now beyond running it, we will talk more about it later. Pine &lt;- read_csv(&quot;PINE_Jan-Mar_2010.csv&quot;) ## Rows: 2160 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): StationID, surrogate ## dbl (5): cfs, year, quarter, month, day ## dttm (1): datetime ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. SNP &lt;- read_csv(&quot;PINE_NFDR_Jan-Mar_2010.csv&quot;) ## Rows: 4320 Columns: 8 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): StationID, surrogate ## dbl (5): cfs, year, quarter, month, day ## dttm (1): datetime ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. RBI &lt;- read_csv(&quot;Flashy_Dat_Subset.csv&quot;) ## Rows: 49 Columns: 26 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): STANAME, STATE, CLASS, AGGECOREGION ## dbl (22): site_no, RBI, RBIrank, DRAIN_SQKM, HUC02, LAT_GAGE, LNG_GAGE, PPTAVG_BASIN, PPTAVG_SITE, T_AVG_BAS... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Basic ggplot syntax 2.3 Our first ggplot Let’s look at the Pine data, plotting streamflow (the cfs column) by the date (datetime column). We will show the time series as a line. ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_line() 2.4 Change point type Now let’s make the same plot but show the data as points, using the pch parameter in geom_point() we can change the point type to any of the following: pch options from R help file ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_point(pch = 8) 2.5 Set colors We can also “easily” change the color. Easily is in quotes because this often trips people up. If you put color = “blue” in the aesthetic function, think about what that is telling ggplot. It says “control the color using”blue”“. That doesn’t make a whole lot of sense, so neither does the output… Try it. What happens is that if color = “blue” is in the aesthetic, you are telling R that the color used in the geom represents “blue”. This is very useful if you have multiple geoms in your plot, are coloring them differently, and are building a legend. But if you are just trying to color the points, it kind of feels like R is trolling you… doesn’t it? Take the color = “blue” out of the aesthetic and you’re golden. ggplot(data = Pine, aes(datetime, y = cfs, color = &quot;blue&quot;))+ geom_point() ggplot(data = Pine, aes(x = datetime, y = cfs))+ geom_point(color = &quot;blue&quot;) 2.6 Controlling color with a third variable and other functions Let’s plot the data as a line again, but play with it a bit. First: make the line blue Second: change the theme See ggplot themes here Third: change the axis labels Fourth: color by discharge See here for changing axis labels and coloring by a variable (in this case discharge) ggplot(data = Pine, aes(x = datetime, y = cfs, color = cfs))+ geom_line()+ ylab(&quot;Discharge (cfs)&quot;)+ xlab(element_blank())+ theme_classic() 2.7 Plotting multiple groups The SNP dataset has two different streams: Pine and NFDR We can look at the two of those a couple of different ways First, make two lines, colored by the stream by adding color = to your aesthetic. ggplot(data = SNP, aes(x = datetime,y = cfs, color = StationID)) + geom_line() 2.8 Facets We can also use facets. You must tell the facet_wrap what variable to use to make the separate panels (facet =). It’ll decide how to orient them or you can tell it how. We want them to be on top of each other so we are going to tell it we want 2 rows by setting nrow = 2. Note that we have to put the column used to make the facets in quotes after facets = ggplot(data = SNP, aes(x = datetime, y = cfs)) + geom_line() + facet_wrap(facets = &quot;StationID&quot;, nrow = 2) 2.9 Two variable faceting You can also use facet_grid() to break your plots up into panels based on two variables. Below we will create a panel for each month in each watershed. Adding scales = “free” allows facet_grid to change the axes. By default, all axes will be the same. This is often what we want, so we can more easily compare magnitudes, but sometimes we are looking for patterns more, so we may want to let the axes have whatever range works for the individual plots. ggplot(data = SNP, aes(x = datetime, y = cfs)) + geom_line() + facet_grid(StationID ~ month, scales = &quot;free&quot;) 2.10 Boxplots We can look at these data in other ways as well. A very useful way to look at the variation of two groups is to use a boxplot. Because the data span several orders of magnitude, we will have to log the y axis to see the differences between the two streams. We do that by adding scale_y_log10() ggplot(data = SNP, aes(x = StationID, y = cfs)) + stat_boxplot()+ scale_y_log10() 2.11 More about color, size, etc Let’s play around a bit with controlling color, point size, etc with other data. We can control the size of points by putting size = in the aes() and color by putting color = If you use a point type that has a background, like #21, you can also set the background color using bg = If points are too close together to see them all you can use a hollow point type or set the alpha lower so the points are transparent (alpha = ) ggplot(RBI, aes(RBI, DRAIN_SQKM, size = T_AVG_SITE, bg = STATE))+ geom_point(pch = 21, alpha = 0.3) 2.12 Multiple geoms Finally: You can add multiple geoms to the same plot. Examples of when you might want to do this are when you are showing a line fit and want to show the points as well, or maybe showing a boxplot and want to show the data behind it. You simply add additional geom_… lines to add additional geoms. ggplot(RBI, aes(RBI, DRAIN_SQKM, color = AGGECOREGION))+ stat_smooth(method = &quot;lm&quot;, linetype = 2)+ geom_point() ## `geom_smooth()` using formula = &#39;y ~ x&#39; "],["data-wrangling-using-tidyverse.html", "Chapter 3 Data wrangling using tidyverse", " Chapter 3 Data wrangling using tidyverse "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
